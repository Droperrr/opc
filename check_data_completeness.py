#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–ª–Ω–æ—Ç—ã —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç—ã
"""

import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import logging
import argparse
from typing import Dict, List, Tuple
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DataCompletenessChecker:
    def __init__(self, db_path: str = 'data/sol_iv.db'):
        self.db_path = db_path
        self.timeframe_minutes = {
            '1m': 1,
            '5m': 5,
            '15m': 15,
            '1h': 60,
            '4h': 240,
            '1d': 1440
        }
    
    def check_data_completeness(self, timeframe: str, market_type: str) -> Dict:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –∏ —Ç–∏–ø–∞ —Ä—ã–Ω–∫–∞
        """
        try:
            conn = sqlite3.connect(self.db_path)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ä—ã–Ω–∫–∞
            table = 'spot_data' if market_type == 'spot' else 'futures_data'
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            query = f"""
            SELECT time FROM {table} 
            WHERE timeframe = ? 
            ORDER BY time
            """
            df = pd.read_sql_query(query, conn, params=[timeframe])
            
            if df.empty:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {market_type} {timeframe}")
                return {
                    'timeframe': timeframe,
                    'market_type': market_type,
                    'start': None,
                    'end': None,
                    'expected_count': 0,
                    'actual_count': 0,
                    'completeness': 0,
                    'gaps': 0,
                    'gap_details': []
                }
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏
            df['time'] = pd.to_datetime(df['time'])
            start = df['time'].min()
            end = df['time'].max()
            
            # –†–∞—Å—á–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
            total_minutes = (end - start).total_seconds() / 60
            expected_count = total_minutes / self.timeframe_minutes[timeframe]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
            df['diff'] = df['time'].diff().dt.total_seconds() / 60
            gaps = df[df['diff'] > self.timeframe_minutes[timeframe] * 1.1]
            
            completeness = (len(df) / expected_count) * 100 if expected_count > 0 else 0
            
            gap_details = []
            if not gaps.empty:
                for _, row in gaps.iterrows():
                    gap_details.append({
                        'time': row['time'].strftime('%Y-%m-%d %H:%M:%S'),
                        'gap_minutes': int(row['diff'])
                    })
            
            conn.close()
            
            return {
                'timeframe': timeframe,
                'market_type': market_type,
                'start': start.strftime('%Y-%m-%d %H:%M:%S'),
                'end': end.strftime('%Y-%m-%d %H:%M:%S'),
                'expected_count': int(expected_count),
                'actual_count': len(df),
                'completeness': round(completeness, 2),
                'gaps': len(gaps),
                'gap_details': gap_details
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ {market_type} {timeframe}: {e}")
            return None
    
    def generate_completeness_report(self, market_types: List[str] = ['spot', 'linear']) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø–æ–ª–Ω–æ—Ç–µ –¥–∞–Ω–Ω—ã—Ö
        """
        logger.info("üîç –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö")
        
        all_results = {}
        total_records = 0
        
        for market_type in market_types:
            market_results = {}
            
            for timeframe in self.timeframe_minutes.keys():
                result = self.check_data_completeness(timeframe, market_type)
                if result:
                    market_results[timeframe] = result
                    total_records += result['actual_count']
                    logger.info(f"‚úÖ {market_type} {timeframe}: {result['completeness']}% ({result['actual_count']} –∑–∞–ø–∏—Å–µ–π)")
            
            all_results[market_type] = market_results
        
        return {
            'results': all_results,
            'total_records': total_records,
            'generated_at': datetime.now().isoformat()
        }
    
    def create_completeness_visualization(self, results: Dict, output_dir: str = 'report_s06'):
        """
        –°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
            data_for_plot = []
            
            for market_type, market_results in results['results'].items():
                for timeframe, result in market_results.items():
                    data_for_plot.append({
                        'Market': market_type,
                        'Timeframe': timeframe,
                        'Completeness': result['completeness'],
                        'Records': result['actual_count']
                    })
            
            df_plot = pd.DataFrame(data_for_plot)
            
            # –ì—Ä–∞—Ñ–∏–∫ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
            plt.figure(figsize=(12, 8))
            
            # –°–æ–∑–¥–∞–µ–º subplot
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
            
            # –ì—Ä–∞—Ñ–∏–∫ –ø–æ–ª–Ω–æ—Ç—ã
            pivot_completeness = df_plot.pivot(index='Timeframe', columns='Market', values='Completeness')
            pivot_completeness.plot(kind='bar', ax=ax1, color=['#1f77b4', '#ff7f0e'])
            ax1.set_title('–ü–æ–ª–Ω–æ—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º', fontsize=14, fontweight='bold')
            ax1.set_ylabel('–ü–æ–ª–Ω–æ—Ç–∞ (%)')
            ax1.set_xlabel('–¢–∞–π–º—Ñ—Ä–µ–π–º')
            ax1.legend(['Spot', 'Futures'])
            ax1.grid(True, alpha=0.3)
            
            # –ì—Ä–∞—Ñ–∏–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π
            pivot_records = df_plot.pivot(index='Timeframe', columns='Market', values='Records')
            pivot_records.plot(kind='bar', ax=ax2, color=['#2ca02c', '#d62728'])
            ax2.set_title('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º', fontsize=14, fontweight='bold')
            ax2.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π')
            ax2.set_xlabel('–¢–∞–π–º—Ñ—Ä–µ–π–º')
            ax2.legend(['Spot', 'Futures'])
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'data_completeness_analysis.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_dir}/data_completeness_analysis.png")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
    
    def export_sample_data(self, output_dir: str = 'report_s06/sample_data'):
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –æ–±—Ä–∞–∑—Ü—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
        """
        try:
            os.makedirs(output_dir, exist_ok=True)
            
            conn = sqlite3.connect(self.db_path)
            
            for market_type in ['spot', 'linear']:
                table = 'spot_data' if market_type == 'linear' else 'futures_data'
                
                for timeframe in self.timeframe_minutes.keys():
                    # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–µ 100 –∑–∞–ø–∏—Å–µ–π –¥–ª—è 1m, 30 –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
                    limit = 100 if timeframe == '1m' else 30
                    
                    query = f"""
                    SELECT * FROM {table} 
                    WHERE timeframe = ? 
                    ORDER BY time 
                    LIMIT {limit}
                    """
                    
                    df = pd.read_sql_query(query, conn, params=[timeframe])
                    
                    if not df.empty:
                        filename = f"{market_type}_data_{timeframe.replace('m', 'm').replace('h', 'h').replace('d', 'd')}_sample.csv"
                        filepath = os.path.join(output_dir, filename)
                        df.to_csv(filepath, index=False)
                        logger.info(f"üíæ –û–±—Ä–∞–∑–µ—Ü —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {filepath} ({len(df)} –∑–∞–ø–∏—Å–µ–π)")
            
            conn.close()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ–±—Ä–∞–∑—Ü–æ–≤: {e}")
    
    def generate_markdown_report(self, results: Dict, output_file: str = 'report_s06/data_summary.md'):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
        """
        try:
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("# –û—Ç—á—ë—Ç –æ —Å–±–æ—Ä–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞ 2025 –≥–æ–¥\n\n")
                
                # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                f.write("## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
                f.write("| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
                f.write("|------------|----------|\n")
                f.write(f"| –û–±—â–∏–π –ø–µ—Ä–∏–æ–¥ | {self._get_period_range(results)} |\n")
                f.write(f"| –¢–∞–π–º—Ñ—Ä–µ–π–º—ã | {', '.join(self.timeframe_minutes.keys())} |\n")
                f.write(f"| –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π | {results['total_records']:,} |\n")
                f.write(f"| –°—Ä–µ–¥–Ω—è—è –ø–æ–ª–Ω–æ—Ç–∞ | {self._calculate_average_completeness(results):.2f}% |\n\n")
                
                # –î–µ—Ç–∞–ª–∏ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
                f.write("## –î–µ—Ç–∞–ª–∏ –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º\n")
                f.write("| –¢–∞–π–º—Ñ—Ä–µ–π–º | –†—ã–Ω–æ–∫ | –ü–µ—Ä–∏–æ–¥ | –û–∂–∏–¥–∞–µ–º–æ | –ü–æ–ª—É—á–µ–Ω–æ | –ü–æ–ª–Ω–æ—Ç–∞ | –ü—Ä–æ–ø—É—Å–∫–∏ |\n")
                f.write("|-----------|-------|--------|----------|----------|---------|----------|\n")
                
                for market_type, market_results in results['results'].items():
                    for timeframe, result in market_results.items():
                        f.write(f"| {timeframe} | {market_type} | {result['start']} - {result['end']} | ")
                        f.write(f"{result['expected_count']:,} | {result['actual_count']:,} | ")
                        f.write(f"{result['completeness']}% | {result['gaps']} |\n")
                
                f.write("\n")
                
                # –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏
                f.write("## –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏\n")
                gaps_found = False
                
                for market_type, market_results in results['results'].items():
                    for timeframe, result in market_results.items():
                        if result['gaps'] > 0:
                            gaps_found = True
                            f.write(f"\n### {market_type} {timeframe}\n")
                            f.write(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤: {result['gaps']}\n")
                            f.write("- –î–µ—Ç–∞–ª–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤:\n")
                            for gap in result['gap_details'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5
                                f.write(f"  - {gap['time']} (–ø—Ä–æ–ø—É—Å–∫ {gap['gap_minutes']} –º–∏–Ω—É—Ç)\n")
                            if len(result['gap_details']) > 5:
                                f.write(f"  - ... –∏ –µ—â–µ {len(result['gap_details']) - 5} –ø—Ä–æ–ø—É—Å–∫–æ–≤\n")
                
                if not gaps_found:
                    f.write("–ü—Ä–æ–ø—É—Å–∫–æ–≤ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.\n")
                
                f.write("\n")
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                f.write("## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n")
                f.write("- –î–ª—è backtesting —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 5m –∫–∞–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ –ø–æ–ª–Ω–æ—Ç–æ–π\n")
                f.write("- –î–ª—è –≤—ã—Å–æ–∫–æ—á–∞—Å—Ç–æ—Ç–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 1m –¥–∞–Ω–Ω—ã–µ —Å —É—á–µ—Ç–æ–º –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤\n")
                f.write("- –î–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 1h –∏ 4h –¥–∞–Ω–Ω—ã–µ\n")
                f.write("- –†–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö –∏ –¥–æ–∑–∞–≥—Ä—É–∂–∞—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏\n")
                
                f.write(f"\n\n*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*")
            
            logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
    
    def _get_period_range(self, results: Dict) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—â–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –ø–µ—Ä–∏–æ–¥–æ–≤"""
        all_starts = []
        all_ends = []
        
        for market_type, market_results in results['results'].items():
            for timeframe, result in market_results.items():
                if result['start']:
                    all_starts.append(result['start'])
                    all_ends.append(result['end'])
        
        if all_starts and all_ends:
            min_start = min(all_starts)
            max_end = max(all_ends)
            return f"{min_start.split()[0]} - {max_end.split()[0]}"
        
        return "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
    
    def _calculate_average_completeness(self, results: Dict) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω—é—é –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö"""
        total_completeness = 0
        count = 0
        
        for market_type, market_results in results['results'].items():
            for timeframe, result in market_results.items():
                total_completeness += result['completeness']
                count += 1
        
        return total_completeness / count if count > 0 else 0

def main():
    parser = argparse.ArgumentParser(description='–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--db', default='data/sol_iv.db', help='–ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--output', default='report_s06', help='–ü–∞–ø–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤')
    parser.add_argument('--markets', nargs='+', default=['spot', 'linear'], 
                       help='–¢–∏–ø—ã —Ä—ã–Ω–∫–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏')
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º —á–µ–∫–µ—Ä
    checker = DataCompletenessChecker(args.db)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    results = checker.generate_completeness_report(args.markets)
    
    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    checker.create_completeness_visualization(results, args.output)
    
    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞–∑—Ü—ã –¥–∞–Ω–Ω—ã—Ö
    checker.export_sample_data(os.path.join(args.output, 'sample_data'))
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown –æ—Ç—á–µ—Ç
    checker.generate_markdown_report(results, os.path.join(args.output, 'data_summary.md'))
    
    logger.info("üéâ –ê–Ω–∞–ª–∏–∑ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω")

if __name__ == "__main__":
    main()
