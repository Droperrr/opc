#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–∏–Ω—É—Ç–Ω—ã—Ö —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞, —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã—Ö —Å —Ç—Ä–µ–Ω–¥–æ–º
"""

import sqlite3
import pandas as pd
from datetime import timedelta
from logger import get_logger

logger = get_logger()

def gen_entries(db='server_opc.db', iv_table='iv_agg', trend_table='signals', iv_timeframe='1m', signal_timeframe='15m', out_csv='entry_points.csv'):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–∏–Ω—É—Ç–Ω—ã–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞, —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ —Å —Ç—Ä–µ–Ω–¥–æ–º"""
    logger.info(f"üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –¥–ª—è IV —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {iv_timeframe} –∏ —Å–∏–≥–Ω–∞–ª–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {signal_timeframe}")
    
    try:
        conn = sqlite3.connect(db)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–≥—Ä–µ–≥–∞—Ç—ã —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É
        iv1 = pd.read_sql_query(f"SELECT * FROM {iv_table} WHERE timeframe = '{iv_timeframe}' ORDER BY time ASC", conn, parse_dates=['time'])
        if iv1.empty:
            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ {iv_table} –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {iv_timeframe}")
            return None
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        iv1 = iv1.rename(columns={'time': 'timestamp', 'iv_30d': 'iv_mean_all', 'skew_30d': 'skew', 'spot_price': 'underlying_price'})
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É
        trend = pd.read_sql_query(f"SELECT * FROM {trend_table} WHERE timeframe = '{signal_timeframe}'", conn, parse_dates=['time'])
        if trend.empty:
            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü–µ {trend_table} –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ {signal_timeframe}")
            return None
        
        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        trend = trend.rename(columns={'time': 'timestamp', 'signal': 'direction'})
        trend = trend.sort_values('timestamp')
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(iv1)} –∑–∞–ø–∏—Å–µ–π –∏ {len(trend)} —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ IV:{iv_timeframe} —Å–∏–≥–Ω–∞–ª:{signal_timeframe}")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞
        spike_threshold = 0.01  # 1% spike
        min_trend_conf = 0.3   # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ç—Ä–µ–Ω–¥–∞
        
        # –í—ã—á–∏—Å–ª—è–µ–º IV spike –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
        iv1['iv_prev5'] = iv1['iv_mean_all'].rolling(5, min_periods=1).mean().shift(1)
        iv1['spike_pct'] = (iv1['iv_mean_all'] - iv1['iv_prev5']) / iv1['iv_prev5'].replace(0, 1)
        
        entries = []
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ IV spike –∏ skew
        if trend.empty:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ IV spike –∏ skew")
            for _, r in iv1.iterrows():
                if abs(r['spike_pct']) >= spike_threshold:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ spike –∏ skew
                    entry_direction = None
                    entry_reason = ""
                    
                    # –ï—Å–ª–∏ IV —Ä–∞—Å—Ç–µ—Ç
                    if r['spike_pct'] > 0:
                        entry_direction = 'BUY'
                        entry_reason = f"IV spike +{r['spike_pct']*100:.1f}%"
                    
                    # –ï—Å–ª–∏ IV –ø–∞–¥–∞–µ—Ç
                    elif r['spike_pct'] < 0:
                        entry_direction = 'SELL'
                        entry_reason = f"IV spike {r['spike_pct']*100:.1f}%"
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ skew
                    elif r['skew'] > 0.01:
                        entry_direction = 'BUY'
                        entry_reason = f"positive skew {r['skew']:.4f}"
                    
                    elif r['skew'] < -0.01:
                        entry_direction = 'SELL'
                        entry_reason = f"negative skew {r['skew']:.4f}"
                    
                    if entry_direction:
                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ spike
                        spike_confidence = min(1.0, abs(r['spike_pct']) * 10)
                        
                        entries.append({
                            'timestamp': r['timestamp'].isoformat(),
                            'direction': entry_direction,
                            'timeframe': iv_timeframe,
                            'confidence': round(spike_confidence, 2),
                            'reason': entry_reason,
                            'underlying_price': r['underlying_price'],
                            'iv_spike': round(r['spike_pct'] * 100, 2),
                            'skew': round(r['skew'], 4),
                            'trend_direction': 'NONE',
                            'trend_confidence': 0.0
                        })
        else:
            for _, r in iv1.iterrows():
                if abs(r['spike_pct']) >= spike_threshold:
                    # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π —Ç—Ä–µ–Ω–¥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª (15m –∏–ª–∏ 1h)
                    current_time = r['timestamp']
                    
                    # –ò—â–µ–º —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –º–∏–Ω—É—Ç
                    recent_trends = trend[trend['timestamp'] >= current_time - timedelta(minutes=30)]
                    
                    if recent_trends.empty:
                        continue
                    
                    # –ë–µ—Ä–µ–º —Å–∞–º—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç—Ä–µ–Ω–¥
                    last_trend = recent_trends.iloc[-1]
                    
                    if last_trend['confidence'] < min_trend_conf:
                        continue
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ spike –∏ —Ç—Ä–µ–Ω–¥–∞
                    entry_direction = None
                    entry_reason = ""
                    
                    # –ï—Å–ª–∏ IV —Ä–∞—Å—Ç–µ—Ç –∏ —Ç—Ä–µ–Ω–¥ BUY/BULLISH
                    if (r['spike_pct'] > 0 and
                        last_trend['direction'] in ['BUY', 'BULLISH']):
                        entry_direction = 'BUY'
                        entry_reason = f"IV spike +{r['spike_pct']*100:.1f}% + {last_trend['direction']} trend"
                    
                    # –ï—Å–ª–∏ IV –ø–∞–¥–∞–µ—Ç –∏ —Ç—Ä–µ–Ω–¥ SELL/BEARISH
                    elif (r['spike_pct'] < 0 and
                          last_trend['direction'] in ['SELL', 'BEARISH']):
                        entry_direction = 'SELL'
                        entry_reason = f"IV spike {r['spike_pct']*100:.1f}% + {last_trend['direction']} trend"
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ skew
                    elif r['skew'] > 0.01 and last_trend['direction'] in ['BUY', 'BULLISH']:
                        entry_direction = 'BUY'
                        entry_reason = f"positive skew {r['skew']:.4f} + {last_trend['direction']} trend"
                    
                    elif r['skew'] < -0.01 and last_trend['direction'] in ['SELL', 'BEARISH']:
                        entry_direction = 'SELL'
                        entry_reason = f"negative skew {r['skew']:.4f} + {last_trend['direction']} trend"
                    
                    if entry_direction:
                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ spike –∏ —Ç—Ä–µ–Ω–¥–∞
                        spike_confidence = min(1.0, abs(r['spike_pct']) * 10)
                        trend_confidence = last_trend['confidence']
                        combined_confidence = (spike_confidence + trend_confidence) / 2
                        
                        entries.append({
                            'timestamp': r['timestamp'].isoformat(),
                            'direction': entry_direction,
                            'timeframe': iv_timeframe,
                            'confidence': round(combined_confidence, 2),
                            'reason': entry_reason,
                            'underlying_price': r['underlying_price'],
                            'iv_spike': round(r['spike_pct'] * 100, 2),
                            'skew': round(r['skew'], 4),
                            'trend_direction': last_trend['direction'],
                            'trend_confidence': last_trend['confidence']
                        })
        
        if entries:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
            df = pd.DataFrame(entries)
            df.to_csv(out_csv, index=False)
            
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(entries)} —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –≤ {out_csv}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
            logger.info("üìã –ü—Ä–∏–º–µ—Ä—ã —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞:")
            print(df.head(5).to_string(index=False))
            
            return df
        else:
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º")
            return None
        
        conn.close()
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞: {e}")
        return None

def generate_entries_for_all_timeframes():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤"""
    logger.info("üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤")
    
    all_entries = []
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ 1m –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
    entries_1m = gen_entries(iv_timeframe='1m', signal_timeframe='15m')
    if entries_1m is not None:
        all_entries.append(entries_1m)
        logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(entries_1m)} —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –¥–ª—è –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ 1m/15m")
    
    # –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ 15m –∞–≥—Ä–µ–≥–∞—Ç–æ–≤
    entries_15m = gen_entries(iv_timeframe='15m', signal_timeframe='15m')
    if entries_15m is not None:
        all_entries.append(entries_15m)
        logger.info(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(entries_15m)} —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –¥–ª—è –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ 15m/15m")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
    if all_entries:
        combined_entries = pd.concat(all_entries, ignore_index=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—â–∏–π —Ñ–∞–π–ª
        combined_entries.to_csv('entry_points_all.csv', index=False)
        
        logger.info(f"üíæ –û–±—â–∏–π —Ñ–∞–π–ª: {len(combined_entries)} —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞")
        
        return combined_entries
    
    return None

def analyze_entry_distribution():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞"""
    try:
        df = pd.read_csv('entry_points.csv')
        
        if df.empty:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        logger.info("üìä –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞:")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º
        direction_counts = df['direction'].value_counts()
        print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º:")
        for direction, count in direction_counts.items():
            print(f"  {direction}: {count}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ confidence
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ confidence:")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ: {df['confidence'].mean():.3f}")
        print(f"  –ú–µ–¥–∏–∞–Ω–∞: {df['confidence'].median():.3f}")
        print(f"  –ú–∏–Ω–∏–º—É–º: {df['confidence'].min():.3f}")
        print(f"  –ú–∞–∫—Å–∏–º—É–º: {df['confidence'].max():.3f}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ IV spike
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ IV spike:")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ: {df['iv_spike'].mean():.2f}%")
        print(f"  –ú–µ–¥–∏–∞–Ω–∞: {df['iv_spike'].median():.2f}%")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ skew
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ skew:")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ: {df['skew'].mean():.4f}")
        print(f"  –ú–µ–¥–∏–∞–Ω–∞: {df['skew'].median():.4f}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è: {e}")

def run_entry_generator_demo():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞"""
    logger.info("üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    all_entries = generate_entries_for_all_timeframes()
    
    if all_entries is not None:
        logger.info("‚úÖ –¢–æ—á–∫–∏ –≤—Ö–æ–¥–∞ —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        analyze_entry_distribution()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"–í—Å–µ–≥–æ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞: {len(all_entries)}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {all_entries['direction'].nunique()}")
        print(f"–¢–∞–π–º—Ñ—Ä–µ–π–º—ã: {all_entries['timeframe'].unique()}")
    
    logger.info("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞
    run_entry_generator_demo()
    
    # –ó–ê–ü–£–°–ö –ê–ì–ï–ù–¢–ê-–ê–ù–ê–õ–ò–¢–ò–ö–ê
    print("\n--- –ó–ê–ü–£–°–ö –ê–ì–ï–ù–¢–ê-–ê–ù–ê–õ–ò–¢–ò–ö–ê ---")
    try:
        from reporting_agent import ReportingAgent
        import pandas as pd
        import os
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not os.path.exists('entry_points.csv'):
            print("\n--- –ê–ì–ï–ù–¢-–ê–ù–ê–õ–ò–¢–ò–ö: –§–∞–π–ª entry_points.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. ---")
        elif os.path.getsize('entry_points.csv') == 0:
            print("\n--- –ê–ì–ï–ù–¢-–ê–ù–ê–õ–ò–¢–ò–ö: –§–∞–π–ª entry_points.csv –ø—É—Å—Ç–æ–π. ---")
        else:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞
            try:
                entry_points_df = pd.read_csv('entry_points.csv')
            except Exception as e:
                entry_points_df = None
                print(f"\n--- –ê–ì–ï–ù–¢-–ê–ù–ê–õ–ò–¢–ò–ö: –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ entry_points.csv: {e} ---")
            
            if entry_points_df is not None and not entry_points_df.empty:
                agent = ReportingAgent()
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
                for index, signal_row in entry_points_df.iterrows():
                    signal_dict = signal_row.to_dict()
                    report_text = agent.analyze_signal(signal_dict)
                    print(report_text)
            else:
                print("\n--- –ê–ì–ï–ù–¢-–ê–ù–ê–õ–ò–¢–ò–ö: –ù–µ—Ç —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. ---")
    except Exception as e:
        print(f"\n--- –ê–ì–ï–ù–¢-–ê–ù–ê–õ–ò–¢–ò–ö: –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–≥–µ–Ω—Ç–∞: {e} ---")
