#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤ v2.0 - –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OI
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Binance Futures –∏ Jupiter Perps –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö Open Interest
–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: 01.08.2025 - 03.09.2025
"""

import pandas as pd
import sqlite3
import numpy as np
import requests
import time
from datetime import datetime, timedelta
from logger import get_logger
import os
import json

logger = get_logger()

class EnhancedSignalGenerator:
    def __init__(self):
        self.signals = []
        self.db_path = 'data/options_enriched.db'
        self.analysis_period = {
            'start': '2025-08-01',
            'end': '2025-09-03',
            'description': '–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≤–µ–¥–µ–Ω –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å 01.08.2025 –ø–æ 03.09.2025'
        }
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–±–Ω–æ–≤–ª–µ–Ω—ã —Å–æ–≥–ª–∞—Å–Ω–æ —Ä—ã–Ω–æ—á–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–µ)
        self.weights = {
            'trend': 0.35,      # –°–Ω–∏–∂–µ–Ω —Å 40% –¥–æ 35%
            'skew': 0.35,       # –ü–æ–≤—ã—à–µ–Ω —Å 30% –¥–æ 35%
            'oi': 0.20,         # –û—Å—Ç–∞–≤–ª–µ–Ω –Ω–∞ 20%
            'volume': 0.10      # –ù–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        }
        
        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        self.thresholds = {
            'min_oi_ratio': 0.01,    # –ú–∏–Ω–∏–º—É–º 1% –æ—Ç —Å—Ä–µ–¥–Ω–µ—Ä—ã–Ω–æ—á–Ω–æ–≥–æ
            'min_volume_sol': 0.5,   # –ú–∏–Ω–∏–º—É–º 0.5 SOL –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
            'confidence_threshold': 0.35,  # –ü–æ–≤—ã—à–µ–Ω —Å 0.25
            'skew_threshold': 0.015   # –ü–æ–≤—ã—à–µ–Ω —Å 0.01
        }
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ (UTC)
        self.sessions = {
            'asian': {'start': 0, 'end': 8},      # 00:00-08:00 UTC
            'european': {'start': 8, 'end': 16},  # 08:00-16:00 UTC
            'american': {'start': 16, 'end': 24}  # 16:00-24:00 UTC
        }
    
    def get_session(self, timestamp):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–æ—Ä–≥–æ–≤—É—é —Å–µ—Å—Å–∏—é –ø–æ –≤—Ä–µ–º–µ–Ω–∏"""
        hour = timestamp.hour
        for session, times in self.sessions.items():
            if times['start'] <= hour < times['end']:
                return session
        return 'american'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    def fetch_binance_oi_data(self, symbol='SOLUSDT'):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ OI —Å Binance Futures API"""
        try:
            # Binance Futures API –¥–ª—è Open Interest
            url = "https://fapi.binance.com/fapi/v1/openInterest"
            params = {'symbol': symbol}
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/json'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ OI —Å Binance: {data.get('openInterest', 0)}")
                return float(data.get('openInterest', 0))
            else:
                logger.warning(f"‚ö†Ô∏è Binance API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å Binance: {e}")
            return None
    
    def fetch_jupiter_perps_data(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å Jupiter Perps (fallback)"""
        try:
            # Jupiter Perps API (–ø—Ä–∏–º–µ—Ä–Ω—ã–π endpoint)
            url = "https://price.jup.ag/v4/price?ids=SOL"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'application/json'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±—ä–µ–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö Jupiter
                volume = data.get('data', {}).get('SOL', {}).get('volume24h', 0)
                logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Å Jupiter: –æ–±—ä–µ–º {volume}")
                return volume
            else:
                logger.warning(f"‚ö†Ô∏è Jupiter API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å Jupiter: {e}")
            return None
    
    def get_real_oi_data(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OI —Å fallback-–º–µ—Ö–∞–Ω–∏–∑–º–æ–º"""
        # –ü—Ä–æ–±—É–µ–º Binance Futures
        binance_oi = self.fetch_binance_oi_data()
        if binance_oi and binance_oi > 0:
            return {
                'source': 'binance_futures',
                'oi_call': binance_oi * 0.6,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                'oi_put': binance_oi * 0.4,
                'total_oi': binance_oi
            }
        
        # Fallback –Ω–∞ Jupiter Perps
        jupiter_volume = self.fetch_jupiter_perps_data()
        if jupiter_volume and jupiter_volume > 0:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—ä–µ–º –≤ OI (–ø—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)
            estimated_oi = jupiter_volume * 0.1  # 10% –æ—Ç –æ–±—ä–µ–º–∞ –∫–∞–∫ OI
            return {
                'source': 'jupiter_perps',
                'oi_call': estimated_oi * 0.55,
                'oi_put': estimated_oi * 0.45,
                'total_oi': estimated_oi
            }
        
        # –ï—Å–ª–∏ –≤—Å–µ API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–º—É–ª—è—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        logger.warning("‚ö†Ô∏è –í—Å–µ API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–º—É–ª—è—Ü–∏—é OI")
        return self.simulate_oi_data()
    
    def simulate_oi_data(self):
        """–°–∏–º—É–ª–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ OI –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π"""
        # –ë–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        base_oi = 1000000  # 1M SOL –∫–∞–∫ –±–∞–∑–æ–≤–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
        # "Solana OI –≤—ã—Ä–æ—Å –Ω–∞ $2,31 –º–ª—Ä–¥ (+84,71%)" - –ø—Ä–∏–º–µ–Ω—è–µ–º —Ä–æ—Å—Ç
        growth_factor = 1.8471
        adjusted_oi = base_oi * growth_factor
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ call/put –Ω–∞ –æ—Å–Ω–æ–≤–µ skew
        call_ratio = 0.6  # –ë–æ–ª—å—à–µ –∫–æ–ª–ª–æ–≤ –≤ —Ç–µ–∫—É—â–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö
        put_ratio = 0.4
        
        return {
            'source': 'simulation_market_data',
            'oi_call': adjusted_oi * call_ratio,
            'oi_put': adjusted_oi * put_ratio,
            'total_oi': adjusted_oi
        }
    
    def load_aggregated_data(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ IV, Skew, OI"""
        try:
            df = pd.read_csv('iv_aggregates_sample.csv')
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            return df
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame()
    
    def load_trend_signals(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–µ–Ω–¥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã"""
        try:
            df = pd.read_csv('trend_signals.csv')
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            logger.info(f"üìà –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")
            return df
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")
            return pd.DataFrame()
    
    def load_entry_points(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ—á–∫–∏ –≤—Ö–æ–¥–∞"""
        try:
            df = pd.read_csv('entry_points.csv')
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            logger.info(f"üéØ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞")
            return df
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞: {e}")
            return pd.DataFrame()
    
    def enhance_data_with_real_oi(self, combined_data):
        """–û–±–æ–≥–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ OI"""
        logger.info("üîÑ –û–±–æ–≥–∞—â–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ OI...")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OI
        oi_data = self.get_real_oi_data()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ OI –∫ –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏
        enhanced_data = []
        for _, row in combined_data.iterrows():
            enhanced_row = row.copy()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ OI
            enhanced_row['oi_call'] = oi_data['oi_call']
            enhanced_row['oi_put'] = oi_data['oi_put']
            enhanced_row['oi_total'] = oi_data['total_oi']
            enhanced_row['oi_source'] = oi_data['source']
            
            # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º OI ratio
            if oi_data['total_oi'] > 0:
                enhanced_row['oi_ratio'] = oi_data['oi_call'] / oi_data['total_oi']
            else:
                enhanced_row['oi_ratio'] = 0.5
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—Ä–≥–æ–≤—É—é —Å–µ—Å—Å–∏—é
            enhanced_row['session'] = self.get_session(row['timestamp'])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞
            enhanced_row['analysis_period'] = f"{self.analysis_period['start']} - {self.analysis_period['end']}"
            
            enhanced_data.append(enhanced_row)
        
        return pd.DataFrame(enhanced_data)
    
    def combine_data(self, agg_data, trend_data, entry_data):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ—Ç–∫–∞–º"""
        combined_data = []
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        trend_dict = {}
        for _, row in trend_data.iterrows():
            timeframe = row['timeframe']
            if timeframe not in trend_dict:
                trend_dict[timeframe] = {}
            trend_dict[timeframe][row['timestamp']] = row
        
        entry_dict = {}
        for _, row in entry_data.iterrows():
            entry_dict[row['timestamp']] = row
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        for _, agg_row in agg_data.iterrows():
            timestamp = agg_row['timestamp']
            timeframe = agg_row['timeframe']
            
            # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–Ω–¥
            trend_info = None
            if timeframe in trend_dict:
                trend_times = list(trend_dict[timeframe].keys())
                if trend_times:
                    valid_trends = [t for t in trend_times if t <= timestamp]
                    if valid_trends:
                        nearest_trend_time = max(valid_trends)
                        trend_info = trend_dict[timeframe][nearest_trend_time]
            
            # –ò—â–µ–º —Ç–æ—á–∫—É –≤—Ö–æ–¥–∞
            entry_info = entry_dict.get(timestamp)
            
            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∑–∞–ø–∏—Å—å
            combined_record = {
                'timestamp': timestamp,
                'timeframe': timeframe,
                'underlying_price': agg_row.get('underlying_price'),
                'iv_mean_all': agg_row.get('iv_mean_all'),
                'iv_call_mean': agg_row.get('iv_call_mean'),
                'iv_put_mean': agg_row.get('iv_put_mean'),
                'skew': agg_row.get('skew'),
                'oi_ratio': agg_row.get('oi_ratio'),
                'skew_percentile': agg_row.get('skew_percentile'),
                'trend_direction': trend_info['direction'] if trend_info is not None else None,
                'trend_confidence': trend_info['confidence'] if trend_info is not None else None,
                'trend_reason': trend_info['reason'] if trend_info is not None else None,
                'entry_direction': entry_info['direction'] if entry_info is not None else None,
                'entry_confidence': entry_info['confidence'] if entry_info is not None else None,
                'entry_reason': entry_info['reason'] if entry_info is not None else None,
                'iv_spike': entry_info['iv_spike'] if entry_info is not None else None
            }
            
            combined_data.append(combined_record)
        
        return pd.DataFrame(combined_data)
    
    def generate_enhanced_signals(self, enhanced_data):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã —Å –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        signals = []
        
        logger.info(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(enhanced_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        for _, row in enhanced_data.iterrows():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if pd.isna(row['underlying_price']) or pd.isna(row['iv_mean_all']):
                continue
            
            signal = None
            confidence = 0.0
            reason = []
            
            # 1. –§–∏–ª—å—Ç—Ä –ø–æ —Ç—Ä–µ–Ω–¥—É (35% –≤–µ—Å–∞)
            if row['trend_direction']:
                if row['trend_direction'] == 'BUY':
                    signal = 'LONG'  # –ò–∑–º–µ–Ω–µ–Ω–æ —Å BUY –Ω–∞ LONG
                    confidence += row['trend_confidence'] * self.weights['trend']
                    reason.append(f"Trend: {row['trend_direction']} (conf: {row['trend_confidence']:.2f})")
                elif row['trend_direction'] == 'SELL':
                    signal = 'SHORT'  # –ò–∑–º–µ–Ω–µ–Ω–æ —Å SELL –Ω–∞ SHORT
                    confidence += row['trend_confidence'] * self.weights['trend']
                    reason.append(f"Trend: {row['trend_direction']} (conf: {row['trend_confidence']:.2f})")
            
            # 2. –§–∏–ª—å—Ç—Ä –ø–æ IV –∏ Skew (35% –≤–µ—Å–∞ - –ø–æ–≤—ã—à–µ–Ω)
            if not pd.isna(row['skew']):
                if row['skew'] > self.thresholds['skew_threshold']:
                    if signal == 'LONG':
                        confidence += self.weights['skew']
                        reason.append(f"Skew bullish: {row['skew']:.4f}")
                    elif signal is None:
                        signal = 'LONG'
                        confidence += self.weights['skew']
                        reason.append(f"Skew bullish: {row['skew']:.4f}")
                elif row['skew'] < -self.thresholds['skew_threshold']:
                    if signal == 'SHORT':
                        confidence += self.weights['skew']
                        reason.append(f"Skew bearish: {row['skew']:.4f}")
                    elif signal is None:
                        signal = 'SHORT'
                        confidence += self.weights['skew']
                        reason.append(f"Skew bearish: {row['skew']:.4f}")
            
            # 3. –§–∏–ª—å—Ç—Ä –ø–æ OI (20% –≤–µ—Å–∞)
            if not pd.isna(row.get('oi_ratio')):
                oi_ratio = row['oi_ratio']
                if oi_ratio > 0.55:
                    if signal == 'LONG':
                        confidence += self.weights['oi']
                        reason.append(f"OI call-heavy: {oi_ratio:.2f}")
                    elif signal is None:
                        signal = 'LONG'
                        confidence += self.weights['oi']
                        reason.append(f"OI call-heavy: {oi_ratio:.2f}")
                elif oi_ratio < 0.45:
                    if signal == 'SHORT':
                        confidence += self.weights['oi']
                        reason.append(f"OI put-heavy: {oi_ratio:.2f}")
                    elif signal is None:
                        signal = 'SHORT'
                        confidence += self.weights['oi']
                        reason.append(f"OI put-heavy: {oi_ratio:.2f}")
            
            # 4. –§–∏–ª—å—Ç—Ä –ø–æ –æ–±—ä–µ–º—É (10% –≤–µ—Å–∞ - –Ω–æ–≤—ã–π)
            if row.get('oi_total', 0) > 0:
                volume_sol = row['oi_total'] / 1000000  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ SOL
                if volume_sol >= self.thresholds['min_volume_sol']:
                    confidence += self.weights['volume']
                    reason.append(f"Volume: {volume_sol:.2f}M SOL")
            
            # 5. –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ –º–∏–Ω—É—Ç–Ω–æ–º—É –≥—Ä–∞—Ñ–∏–∫—É
            if row['entry_direction'] and row['entry_direction'] == signal:
                confidence += row['entry_confidence'] * 0.1
                reason.append(f"1m confirmation: {row['entry_direction']}")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º confidence –¥–æ 0-1
            confidence = min(1.0, max(0.0, confidence))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ confidence >= –ø–æ—Ä–æ–≥–∞
            if signal and confidence >= self.thresholds['confidence_threshold']:
                signals.append({
                    'timestamp': row['timestamp'].isoformat(),
                    'symbol': 'SOL',
                    'strike': row.get('underlying_price', 0),
                    'expiry': '2025-09-26',  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –¥–∞—Ç–∞ —ç–∫—Å–ø–∏—Ä–∞—Ü–∏–∏
                    'signal': signal,
                    'direction': signal,  # –î—É–±–ª–∏—Ä—É–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    'confidence': round(confidence, 3),
                    'reason': ' | '.join(reason),
                    'underlying_price': row['underlying_price'],
                    'timeframe': row['timeframe'],
                    'iv': row['iv_mean_all'],
                    'skew': row['skew'],
                    'oi_call': row.get('oi_call', 0),
                    'oi_put': row.get('oi_put', 0),
                    'oi_ratio': row.get('oi_ratio', 0.5),
                    'oi_source': row.get('oi_source', 'unknown'),
                    'trend_15m': row.get('trend_direction'),
                    'trend_1h': row.get('trend_direction'),
                    'session': row.get('session', 'unknown'),
                    'analysis_period': row.get('analysis_period', '')
                })
        
        return signals
    
    def save_enhanced_signals(self, signals):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã –≤ CSV —Ñ–∞–π–ª"""
        if signals:
            df = pd.DataFrame(signals)
            df.to_csv('signals_enhanced.csv', index=False)
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(signals)} —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ signals_enhanced.csv")
            return df
        else:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return pd.DataFrame()
    
    def generate_enhanced_statistics(self, signals_df):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–∏–≥–Ω–∞–ª–∞–º"""
        if signals_df.empty:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
            return
        
        stats = {
            'total_signals': len(signals_df),
            'long_signals': len(signals_df[signals_df['signal'] == 'LONG']),
            'short_signals': len(signals_df[signals_df['signal'] == 'SHORT']),
            'avg_confidence': signals_df['confidence'].mean(),
            'avg_iv': signals_df['iv'].mean(),
            'avg_skew': signals_df['skew'].mean(),
            'avg_oi_ratio': signals_df['oi_ratio'].mean()
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Å–µ—Å—Å–∏—è–º
        session_stats = signals_df.groupby('session').agg({
            'signal': 'count',
            'confidence': 'mean',
            'iv': 'mean',
            'skew': 'mean'
        }).round(3)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ñ—Ä–µ–π–º–∞–º
        timeframe_stats = signals_df.groupby('timeframe').agg({
            'signal': 'count',
            'confidence': 'mean',
            'iv': 'mean',
            'skew': 'mean'
        }).round(3)
        
        logger.info("üìä –£–ª—É—á—à–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤:")
        logger.info(f"   –í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {stats['total_signals']}")
        logger.info(f"   LONG: {stats['long_signals']}, SHORT: {stats['short_signals']}")
        logger.info(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats['avg_confidence']:.3f}")
        logger.info(f"   –°—Ä–µ–¥–Ω—è—è IV: {stats['avg_iv']:.3f}")
        logger.info(f"   –°—Ä–µ–¥–Ω–∏–π Skew: {stats['avg_skew']:.4f}")
        logger.info(f"   –°—Ä–µ–¥–Ω–∏–π OI ratio: {stats['avg_oi_ratio']:.3f}")
        
        logger.info("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ—Ä–≥–æ–≤—ã–º —Å–µ—Å—Å–∏—è–º:")
        for session, data in session_stats.iterrows():
            logger.info(f"   {session}: {data['signal']} —Å–∏–≥–Ω–∞–ª–æ–≤, conf: {data['confidence']:.3f}")
        
        logger.info("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —Ñ—Ä–µ–π–º–∞–º:")
        for timeframe, data in timeframe_stats.iterrows():
            logger.info(f"   {timeframe}: {data['signal']} —Å–∏–≥–Ω–∞–ª–æ–≤, conf: {data['confidence']:.3f}")
        
        return stats
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–∏–≥–Ω–∞–ª–æ–≤"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ v2.0...")
        logger.info(f"üìÖ –ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: {self.analysis_period['description']}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        agg_data = self.load_aggregated_data()
        trend_data = self.load_trend_signals()
        entry_data = self.load_entry_points()
        
        if agg_data.empty:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            return
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        combined_data = self.combine_data(agg_data, trend_data, entry_data)
        logger.info(f"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(combined_data)} –∑–∞–ø–∏—Å–µ–π")
        
        # –û–±–æ–≥–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–º–∏ OI
        enhanced_data = self.enhance_data_with_real_oi(combined_data)
        logger.info(f"üìä –û–±–æ–≥–∞—â–µ–Ω–æ {len(enhanced_data)} –∑–∞–ø–∏—Å–µ–π —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ OI")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
        signals = self.generate_enhanced_signals(enhanced_data)
        logger.info(f"üéØ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(signals)} —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals_df = self.save_enhanced_signals(signals)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if not signals_df.empty:
            self.generate_enhanced_statistics(signals_df)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å–∏–≥–Ω–∞–ª–æ–≤
            logger.info("üìã –ü—Ä–∏–º–µ—Ä—ã —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤:")
            for i, signal in enumerate(signals[:3]):
                logger.info(f"   {i+1}. [{signal['timestamp']}] {signal['signal']} | "
                           f"Conf: {signal['confidence']:.3f} | "
                           f"Price: {signal['underlying_price']} | "
                           f"Session: {signal['session']} | "
                           f"OI Source: {signal['oi_source']} | "
                           f"Reason: {signal['reason'][:40]}...")
        else:
            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–∏–≥–Ω–∞–ª—ã")

if __name__ == "__main__":
    generator = EnhancedSignalGenerator()
    generator.run()
